Homework 5
================
Fangyi Chen
2023-11-15

``` r
library(tidyverse)
library(ggridges)
library(rvest)
library(broom)
```

## Problem 2

``` r
file_names = list.files("data")

combined_df = map_df(file_names, ~{
  df = read_csv(file.path("data", .x), show_col_types = FALSE)
  
  subject_id = str_extract(.x, "\\d+")
  
  arm = str_extract(.x, "(con|exp)")
  
  df |> 
    mutate(subject_id = subject_id,
           arm = arm) |> 
    select(subject_id, arm, everything())
  
})
```

``` r
combined_df |> 
      pivot_longer(week_1:week_8,
                 names_to = "week",
                 names_prefix = "week_" ,
                 values_to = "observation") |> 
  ggplot(aes(x=week,y= observation, group=subject_id, color=arm)) +
  geom_line() + 
  facet_grid(. ~arm) +
  labs(title = "Spaghetti Plot of Observations Over Time",
       x = "Week",
       y = "Observation") 
```

![](p8105_hw5_fc2718_files/figure-gfm/spaghetti%20plot-1.png)<!-- -->

### Comments: In the experiment arm , we did perceive a increasing trend from week 1 to week8, whereas for control group, there appears to have difference between week1 and week8 in the end.

## Problem 3

``` r
set.seed(1)

list_mu = c (0, 1, 2, 3, 4, 5, 6)

gather_test_results = function(mu) {

  n = 30
  sigma = 5
  
  simulated_data =rnorm(n=n, mean=mu, sd=sigma)
  test_results = tibble(tidy(t.test(simulated_data, mu=0)))
  
  
  return (tibble(
    true_mean = mu,
    p_value = test_results$p.value,
    estimated_mu = test_results$estimate
    
  ))
}

sim_results_df = 
  expand_grid(
    true_mu = list_mu,
    no_sample = 1:5000
  ) |> 
  mutate(
    estimate_df = map(true_mu, gather_test_results)
  ) |> 
  unnest(estimate_df)
```

``` r
alpha = 0.05
sim_results_df |> 
  group_by(true_mu) |> 
  summarise(power = mean(p_value < alpha),
            avg_estimate  = mean(estimated_mu)) |> 
  ggplot(aes(x=true_mu, y = power)) +
  geom_line() +
  labs(title = "Effect Size and Power",
       x = "True Value of mean",
       y = "Power") 
```

![](p8105_hw5_fc2718_files/figure-gfm/plot%20effect%20size%20and%20power-1.png)<!-- -->

### As shown on plot, when we increase the effect size (difference between the true population mean and null hypothesis mean), we perceive a higher power of the statistical test. On the contrary, as we decreases the effect size, lower power or smaller statistical difference can be found.

``` r
sim_results_df |> 
  group_by(true_mu) |> 
  summarise(avg_estimate_reject  = mean(estimated_mu)) |> 
  ggplot(aes(x=true_mu, y = avg_estimate_reject)) +
  geom_line() +
  labs(title = "Estimated mu i and True Value of mu",
       x = "True Value of mean",
       y = "Average estimate mu") 
```

![](p8105_hw5_fc2718_files/figure-gfm/plot%20of%20estimate%20mu%20and%20true%20mu-1.png)<!-- -->

``` r
sim_results_df |> 
  filter(p_value < alpha) |> 
  group_by(true_mu) |> 
  summarise(avg_estimate_reject  = mean(estimated_mu)) |> 
  ggplot(aes(x=true_mu, y = avg_estimate_reject)) +
  geom_line() +
  labs(title = "Estimated mu in Rejected and True Value of mu",
       x = "True Value of mean",
       y = "Average estimate mu (rejected)") 
```

![](p8105_hw5_fc2718_files/figure-gfm/plot%20of%20estimate%20mu%20(rejected)%20and%20true%20mu-1.png)<!-- -->

### Comments: based on the graph, the estimated mu in rejected samples is necessarily equal to the true population mean. There are several reasons attribute to that. One of that was that the generated samples are subject to random sampling variability, thus it is possible to generate samples with different estimated mean. Additionally, it is important to note that we calcualte the average estimate of mean in samples where null hypothesis is rejected. In this casem we are more likely to overestimate the true effect size.
